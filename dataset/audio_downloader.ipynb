{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd320cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joey/Workspace/interPro/ASR/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 3112 examples [00:00, 45907.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"AIxBlock/Human-to-machine-Japanese-audio-call-center-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d82178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joey/Workspace/interPro/ASR/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"reazon-research/reazonspeech\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f250d9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['name', 'audio', 'transcription'],\n",
       "        num_rows: 5323\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51dfbd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/Users/joey/.cache/huggingface/datasets/downloads/extracted/6931f71321a9af351e7e177c78bee3da636dbc9151fcfbc2b8e14cf9c0b3ab91/000/000734dcb35d6.flac',\n",
       " 'array': array([-0.01309204, -0.01068115, -0.006073  , ...,  0.00613403,\n",
       "         0.00558472,  0.00674438], shape=(22291,)),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][\"audio\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5bcde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grewfefa777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['name', 'audio', 'transcription']\n",
      "\n",
      "First sample with all fields:\n",
      "dict_keys(['name', 'audio', 'transcription'])\n",
      "\n",
      "Sample data (excluding large audio array):\n",
      "  name: 000/000734dcb35d6.flac\n",
      "  audio: [audio data with shape (22291,)]\n",
      "  transcription: „Åì„Çå„Åæ„Åü„Ç∏„Éü„Éº„Åï„Çì\n"
     ]
    }
   ],
   "source": [
    "# Check all available fields in the dataset\n",
    "print(\"Dataset columns:\", ds.column_names)\n",
    "print(\"\\nFirst sample with all fields:\")\n",
    "print(ds[0].keys())\n",
    "print(\"\\nSample data (excluding large audio array):\")\n",
    "for key, value in ds[0].items():\n",
    "    if key != 'audio':\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: [audio data with shape {value['array'].shape}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "uw28bb8tzu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 10 audio samples with transcripts to: /Users/joey/Workspace/interPro/ASR/dataset/sample_audios\n",
      "================================================================================\n",
      "‚úì Sample 000: audio_000.wav (1.39s)\n",
      "  Transcript: „Åì„Çå„Åæ„Åü„Ç∏„Éü„Éº„Åï„Çì\n",
      "‚úì Sample 001: audio_001.wav (7.65s)\n",
      "  Transcript: ‰ªä„ÇÇÁõ∏Êâã„Å´„É≠„É≥„Éê„É´„Éâ„ÅÆ„Åª„ÅÜ„Å´ËÇ©Âè£„ÅßÊè°„Çâ„Çå„Å¶„ÇÇ„Åô„Åê„Åï„ÅæÊµÅ„Çå„ÇíÂàá„ÇãÂºï„ÅçËæº„ÅøËøî„Åó„Å´Â§â„Åà„Åü„Å®„ÄÇ\n",
      "‚úì Sample 002: audio_002.wav (2.94s)\n",
      "  Transcript: ÂÉï„ÅØ„Çø„ÇØ„Ç∑„Éº„ÅÆ„Åì„Å®„Å´Èñ¢„Åó„Å¶„ÅØ„ÅÇ„Çì„Åæ„Çä„Åì„ÅÜ„ÄÇ\n",
      "‚úì Sample 003: audio_003.wav (4.78s)\n",
      "  Transcript: Ôºª„Éê„Éº„Éü„É§„É≥„Ç∫„Ç™„É≥„Ç®„Ç¢Áç≤Âæó„ÇÇÁñëÊÉëÊµÆ‰∏äÔºΩ\n",
      "‚úì Sample 004: audio_004.wav (4.63s)\n",
      "  Transcript: „Åù„Åó„Å¶„ÇÇ„ÅÜ‰∏ÄÊûö„Åå„Åì„Å°„Çâ„ÄÇ\n",
      "‚úì Sample 005: audio_005.wav (0.62s)\n",
      "  Transcript: ‰ΩïÔºü\n",
      "‚úì Sample 006: audio_006.wav (8.15s)\n",
      "  Transcript: Á©çÊ•µÁöÑ„Å´„ÅäÈáë„Çí‰Ωø„ÅÜ„Åπ„Åç„Å†„Å®‰∏ªÂºµ„Åô„ÇãÊîøÊ≤ªÂÆ∂„ÇÑÁúÅÂ∫Å„Å®ÊîØÂá∫„ÇíÊäë„Åà„Åü„ÅÑË≤°ÂãôÁúÅ„Å®„ÅÆÈñì„Åß„Åõ„ÇÅ„ÅéÂêà„ÅÑ„ÅåÁ∂ö„Åç„Åæ„Åô„ÄÇ\n",
      "‚úì Sample 007: audio_007.wav (5.26s)\n",
      "  Transcript: ‰ªäÂ§ß‰ºö„ÅÆ„Éú„Ç≠„ÅÆÊ≥≥„ÅéÊùâÂÜÖ„Åï„Çì„ÅØ„Å©„ÅÜÊÑü„Åò„Å¶„Çâ„Å£„Åó„ÇÉ„ÅÑ„Åæ„Åô„ÅãÔºü\n",
      "‚úì Sample 008: audio_008.wav (6.12s)\n",
      "  Transcript: „Åù„Åó„Å¶ÂæóÁÇπ„ÇíÈòªÊ≠¢„Åô„Çã„Åü„ÇÅÁõ∏Êâã„ÅØ„Éú„Éº„É´„ÇíÁô∫Â∞ÑÔºÅ\n",
      "‚úì Sample 009: audio_009.wav (6.71s)\n",
      "  Transcript: „ÇÑ„ÅØ„Çä„Ç™„Ç¶„ÉüÂàù„ÅÆÂ•≥ÊÄßÂΩπÂì°„ÅØÂ§èÁõÆ„Åï„Çì„Åã„Å™„ÄÇ\n",
      "================================================================================\n",
      "\n",
      "‚úì Saved 10 samples to: /Users/joey/Workspace/interPro/ASR/dataset/sample_audios\n",
      "‚úì Metadata saved to: /Users/joey/Workspace/interPro/ASR/dataset/sample_audios/metadata.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"sample_audios\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Number of samples to save\n",
    "num_samples = 10\n",
    "\n",
    "print(f\"Saving {num_samples} audio samples with transcripts to: {output_dir.absolute()}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "saved_data = []\n",
    "\n",
    "for i in range(min(num_samples, len(ds))):\n",
    "    sample = ds[i]\n",
    "    \n",
    "    # Extract audio\n",
    "    audio_array = sample['audio']['array']\n",
    "    sample_rate = sample['audio']['sampling_rate']\n",
    "    duration = len(audio_array) / sample_rate\n",
    "    \n",
    "    # Create filenames\n",
    "    audio_filename = f\"audio_{i:03d}.wav\"\n",
    "    transcript_filename = f\"audio_{i:03d}.txt\"\n",
    "    \n",
    "    audio_path = output_dir / audio_filename\n",
    "    transcript_path = output_dir / transcript_filename\n",
    "    \n",
    "    # Save audio file\n",
    "    sf.write(audio_path, audio_array, sample_rate)\n",
    "    \n",
    "    # Extract transcript (check multiple possible field names)\n",
    "    transcript = None\n",
    "    for field in ['transcript', 'transcription', 'text', 'sentence']:\n",
    "        if field in sample:\n",
    "            transcript = sample[field]\n",
    "            break\n",
    "    \n",
    "    # Save transcript if available\n",
    "    if transcript:\n",
    "        with open(transcript_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(transcript)\n",
    "    else:\n",
    "        transcript = \"[No transcript available]\"\n",
    "    \n",
    "    # Store metadata\n",
    "    metadata = {\n",
    "        'index': i,\n",
    "        'audio_file': audio_filename,\n",
    "        'transcript_file': transcript_filename if transcript != \"[No transcript available]\" else None,\n",
    "        'transcript': transcript,\n",
    "        'duration_seconds': round(duration, 2),\n",
    "        'sample_rate': sample_rate\n",
    "    }\n",
    "    saved_data.append(metadata)\n",
    "    \n",
    "    print(f\"‚úì Sample {i:03d}: {audio_filename} ({duration:.2f}s)\")\n",
    "    print(f\"  Transcript: {transcript[:100]}{'...' if len(str(transcript)) > 100 else ''}\")\n",
    "\n",
    "# Save metadata to JSON file\n",
    "metadata_path = output_dir / \"metadata.json\"\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(saved_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úì Saved {len(saved_data)} samples to: {output_dir.absolute()}\")\n",
    "print(f\"‚úì Metadata saved to: {metadata_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3v5hbrlzhm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample 0:\n",
      "  Audio file: audio_000.wav\n",
      "  Duration: 1.39s\n",
      "  Sample rate: 16000 Hz\n",
      "  Transcript: „Åì„Çå„Åæ„Åü„Ç∏„Éü„Éº„Åï„Çì\n",
      "\n",
      "Total samples saved: 10\n"
     ]
    }
   ],
   "source": [
    "# Example: Load and use the saved audio and transcript\n",
    "sample_idx = 0\n",
    "\n",
    "# Load audio\n",
    "audio_file = output_dir / f\"audio_{sample_idx:03d}.wav\"\n",
    "transcript_file = output_dir / f\"audio_{sample_idx:03d}.txt\"\n",
    "\n",
    "audio, sr = sf.read(audio_file)\n",
    "\n",
    "# Load transcript\n",
    "with open(transcript_file, 'r', encoding='utf-8') as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "print(f\"Loaded sample {sample_idx}:\")\n",
    "print(f\"  Audio file: {audio_file.name}\")\n",
    "print(f\"  Duration: {len(audio) / sr:.2f}s\")\n",
    "print(f\"  Sample rate: {sr} Hz\")\n",
    "print(f\"  Transcript: {transcript}\")\n",
    "\n",
    "# Load metadata\n",
    "with open(output_dir / \"metadata.json\", 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"\\nTotal samples saved: {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5w0l9m3b",
   "metadata": {},
   "source": [
    "# üìÅ Saved Files Structure\n",
    "\n",
    "The `sample_audios/` folder now contains:\n",
    "\n",
    "```\n",
    "sample_audios/\n",
    "‚îú‚îÄ‚îÄ audio_000.wav          # Audio file 1\n",
    "‚îú‚îÄ‚îÄ audio_000.txt          # Transcript for audio 1\n",
    "‚îú‚îÄ‚îÄ audio_001.wav          # Audio file 2\n",
    "‚îú‚îÄ‚îÄ audio_001.txt          # Transcript for audio 2\n",
    "‚îú‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ audio_009.wav          # Audio file 10\n",
    "‚îú‚îÄ‚îÄ audio_009.txt          # Transcript for audio 10\n",
    "‚îî‚îÄ‚îÄ metadata.json          # Complete metadata for all samples\n",
    "```\n",
    "\n",
    "## metadata.json Format:\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"index\": 0,\n",
    "    \"audio_file\": \"audio_000.wav\",\n",
    "    \"transcript_file\": \"audio_000.txt\",\n",
    "    \"transcript\": \"The actual transcript text...\",\n",
    "    \"duration_seconds\": 54.16,\n",
    "    \"sample_rate\": 44100\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "## Usage with ASR Systems:\n",
    "\n",
    "You can now test your ASR systems and compare with ground truth transcripts!\n",
    "\n",
    "```python\n",
    "# Test ASR system\n",
    "predicted_transcript = your_asr_system('sample_audios/audio_000.wav')\n",
    "\n",
    "# Compare with ground truth\n",
    "with open('sample_audios/audio_000.txt', 'r') as f:\n",
    "    ground_truth = f.read()\n",
    "\n",
    "print(f\"Ground truth: {ground_truth}\")\n",
    "print(f\"Predicted:    {predicted_transcript}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbe5728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Audio saved to: /Users/joey/Workspace/interPro/ASR/dataset/call_center_sample_0.wav\n",
      "  Duration: 54.18 seconds\n",
      "  Sample rate: 44100 Hz\n",
      "  File size: 4666.5 KB\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "# Save the first audio sample to a local WAV file\n",
    "output_dir = Path(\".\")\n",
    "output_file = output_dir / \"call_center_sample_0.wav\"\n",
    "\n",
    "# Extract audio data\n",
    "audio_array = ds[0]['audio']['array']\n",
    "sample_rate = ds[0]['audio']['sampling_rate']\n",
    "\n",
    "# Save to WAV file\n",
    "sf.write(output_file, audio_array, sample_rate)\n",
    "\n",
    "print(f\"‚úì Audio saved to: {output_file.absolute()}\")\n",
    "print(f\"  Duration: {len(audio_array) / sample_rate:.2f} seconds\")\n",
    "print(f\"  Sample rate: {sample_rate} Hz\")\n",
    "print(f\"  File size: {output_file.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aittcxtyf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save multiple audio samples (5 samples)\n",
    "num_samples = 5\n",
    "saved_files = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = ds[i]\n",
    "    audio_array = sample['audio']['array']\n",
    "    sample_rate = sample['audio']['sampling_rate']\n",
    "    \n",
    "    output_file = output_dir / f\"call_center_sample_{i}.wav\"\n",
    "    sf.write(output_file, audio_array, sample_rate)\n",
    "    \n",
    "    duration = len(audio_array) / sample_rate\n",
    "    saved_files.append({\n",
    "        'index': i,\n",
    "        'file': str(output_file),\n",
    "        'duration': duration\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úì Sample {i}: {output_file.name} ({duration:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duvfnaikbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file back from disk\n",
    "test_file = saved_files[0]['file']\n",
    "audio_loaded, sr_loaded = sf.read(test_file)\n",
    "\n",
    "print(f\"Loaded audio from: {test_file}\")\n",
    "print(f\"  Shape: {audio_loaded.shape}\")\n",
    "print(f\"  Sample rate: {sr_loaded} Hz\")\n",
    "print(f\"  Duration: {len(audio_loaded) / sr_loaded:.2f}s\")\n",
    "print(f\"  Data type: {audio_loaded.dtype}\")\n",
    "\n",
    "# Show how to use with ASR systems\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"How to Use These Audio Files:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Kotoba Whisper (optimized):\")\n",
    "print(f\"   !python ../test_asr_optimized.py {test_file}\")\n",
    "print(f\"\\n2. Kotoba Whisper (streaming):\")\n",
    "print(f\"   !python ../test_asr_streaming.py --mode file --audio {test_file}\")\n",
    "print(f\"\\n3. AssemblyAI (batch):\")\n",
    "print(f\"   !python ../test_asr_assemblyai.py --audio {test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j8vlrmzsauh",
   "metadata": {},
   "source": [
    "# Summary: Audio Loading Process\n",
    "\n",
    "## What You Just Did:\n",
    "\n",
    "1. **Loaded Dataset** - Successfully loaded 3,112 Japanese call center audio samples from HuggingFace\n",
    "2. **Extracted Audio** - Got the audio as NumPy arrays with shape information\n",
    "3. **Saved to Local Files** - Saved audio samples as WAV files to disk\n",
    "4. **Loaded Back** - Verified you can load the saved WAV files\n",
    "\n",
    "## Audio Data Structure:\n",
    "\n",
    "The dataset provides audio in this format:\n",
    "```python\n",
    "{\n",
    "    'audio': {\n",
    "        'path': 'zip://...',           # Original location in cache\n",
    "        'array': numpy.ndarray,         # Audio samples as array\n",
    "        'sampling_rate': 44100          # Sample rate in Hz\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## How to Use the Audio Files:\n",
    "\n",
    "### Method 1: Load from saved WAV file\n",
    "```python\n",
    "import soundfile as sf\n",
    "audio_array, sample_rate = sf.read('call_center_sample_0.wav')\n",
    "```\n",
    "\n",
    "### Method 2: Load directly from dataset\n",
    "```python\n",
    "audio_array = ds[0]['audio']['array']\n",
    "sample_rate = ds[0]['audio']['sampling_rate']\n",
    "```\n",
    "\n",
    "### Method 3: Use with ASR scripts\n",
    "Run the audio through your ASR systems using the saved WAV files!\n",
    "\n",
    "## Next Steps:\n",
    "- Test these audio files with your ASR systems\n",
    "- Compare transcription quality across different systems\n",
    "- Download more samples as needed (you have 3,112 available!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
